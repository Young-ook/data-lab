{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (ML) Basic\n",
    "## Dataset\n",
    "A data is an essential component of ML model and, a dataset definition in ML is “a collection of data that is treated as a single unit by a computer”. This means that a dataset contains a lot of separate pieces of data, but can be used to teach the machine learning algorithm to find predictable patterns inside the whole dataset.\n",
    "\n",
    "**Splitting the Data: Training, Testing, and Validation Datasets in ML** - Usually, a dataset is used not only for training purposes. A single training set that has already been processed is usually split into several types of datasets in machine learning, which is needed to check how well the training of the model went. For this purpose, a testing dataset is typically separated from the data. Next, a validation dataset, while not strictly crucial, is quite helpful to avoid training your algorithm on the same type of data and making biased predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[30, 100], [20, 50], [35, 72], [25, 80], [30, 70], [40, 60]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "data = [[30, 100], [20, 50], [35, 72],\n",
    "        [25, 80], [30, 70], [40, 60]]\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "One of the most well-known repositories for machine learning datasets is the [UCI Machien Learning Repository](https://archive.ics.uci.edu/). Most of the datasets over there are small in size because the technology at the time was not advanced enough to handle larger size data. Newer datasets are usually larger in size. For example, the ImageNet dataset is over 160 GB. These datasets are commonly found in [Kaggle](https://www.kaggle.com/datasets), and we can search them by name and download. [OpenML](https://www.openml.org/) is also, a repository that hosts a lot of datasets. It is convenient because you can search for the dataset by name, but it also has a standardized web API for users to retrieve data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The repositories described above are a good place to start getting datasets, but you may also obtain datasets simply by downloading them from the web using a browser, the command line, a network library such as the wget tool, or a request in Python. *Scikit-learn* is an example where you can download the dataset using its API. Because some of these datasets have become standards or benchmarks, many machine learning libraries have created functions to help you retrieve them. For practical reasons, the datasets often don't come with the library and are downloaded in real time when you call the function, so you'll need a stable internet connection to use them. The related functions are defined under [`sklearn.datasets`](https://scikit-learn.org/stable/api/sklearn.datasets.html), and you may see the list of functions at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "...       ...       ...       ...        ...         ...       ...       ...   \n",
      "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
      "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
      "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
      "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
      "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
      "\n",
      "       Longitude  MedHouseVal  \n",
      "0        -122.23        4.526  \n",
      "1        -122.22        3.585  \n",
      "2        -122.24        3.521  \n",
      "3        -122.25        3.413  \n",
      "4        -122.25        3.422  \n",
      "...          ...          ...  \n",
      "20635    -121.09        0.781  \n",
      "20636    -121.21        0.771  \n",
      "20637    -121.22        0.923  \n",
      "20638    -121.32        0.847  \n",
      "20639    -121.24        0.894  \n",
      "\n",
      "[20640 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "# load california housing dataset (regression)\n",
    "data = sklearn.datasets.fetch_california_housing(return_X_y=False, as_frame=True)\n",
    "data = data[\"frame\"]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One good thing tat scikit-learn provides is the convenient ability to read any dataset from OpenML. Read dataset and run the logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass  Sex  Age  Fare  Embarked  relatives  Title\n",
      "0           0       3    0    2     0         0          1      1\n",
      "1           1       1    1    5     3         1          1      3\n",
      "2           1       3    1    3     0         0          0      2\n",
      "3           1       1    1    5     3         0          1      3\n",
      "4           0       3    0    5     1         0          0      1\n",
      "..        ...     ...  ...  ...   ...       ...        ...    ...\n",
      "886         0       2    0    3     1         0          0      5\n",
      "887         1       1    1    2     2         0          0      2\n",
      "888         0       3    1    1     2         0          3      2\n",
      "889         1       1    0    3     2         1          0      1\n",
      "890         0       3    0    4     0         2          0      1\n",
      "\n",
      "[891 rows x 8 columns]\n",
      "Accuracy: 0.8114478114478114\n",
      "Coefficient: [[-0.75486619  2.23758245 -0.20788379  0.2806995   0.24340651 -0.36705508\n",
      "   0.47881365]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "#data = fetch_openml(\"diabetes\", version=1, as_frame=True, return_X_y=False)\n",
    "data = fetch_openml(\"titanic\", version=6, as_frame=True, return_X_y=False)\n",
    "print(data[\"frame\"])\n",
    "\n",
    "x, y = fetch_openml(\"titanic\", version=6, as_frame=False, return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(x, y)\n",
    "print(\"Accuracy: {:,}\".format(clf.score(x, y)))   # accuracy\n",
    "print(\"Coefficient:\", clf.coef_)                  # coefficient in logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types: Structured, Semi-structured, Unstructured\n",
    "### Structured data\n",
    "Structured data has clearly defined data types (e.g. “name” would be a string and “price” would be a float). Usually, structured data can be indexed. Roughly, if it is tabular, it is structured. \n",
    "- Common forms of structured data:\n",
    "  - Spreadsheets\n",
    "  - Tables in a SQL database\n",
    "  - Vectors, matrices and n-dimensional arrays\n",
    "- Common examples:\n",
    "  - Daily stock market information\n",
    "  - An inventory of a particular business\n",
    "  - Daily marketing performance metrics\n",
    "### Semi-structured Data\n",
    "[Semi-structured data](https://en.wikipedia.org/wiki/Semi-structured_data) is a form of structured data that does not obey the tabular structure of data models associated with relational databases or other forms of data tables, but nonetheless contains tags or other markers to separate semantic elements and enforce hierarchies of records and fields within the data. Therefore, it is also known as self-describing structure. Semi-structured data are increasingly occurring since the advent of the Internet where full-text documents and databases are not the only forms of data anymore, and different applications need a medium for exchanging information. In object-oriented databases, one often finds semi-structured data.\n",
    "- Common forms of semi-structured data:\n",
    "  - XML (eXtensible Markup Language) and other markup languages files\n",
    "  - JSON (JavaScript Object Notation) and other data interchange format files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>Firebolt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>Pewter Cauldron</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>Dragon Hide Gloves</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>Polyjuice Potion</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>Weasley Is Our King Buttons</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_id customer_id                      product  quantity\n",
       "0      100           1                     Firebolt         1\n",
       "1      101           1              Pewter Cauldron        18\n",
       "2      102           3           Dragon Hide Gloves        10\n",
       "3      103           4             Polyjuice Potion         6\n",
       "4      104           4  Weasley Is Our King Buttons       120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   order_id     5 non-null      object\n",
      " 1   customer_id  5 non-null      object\n",
      " 2   product      5 non-null      object\n",
      " 3   quantity     5 non-null      int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 292.0+ bytes\n",
      "None \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customerName</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>100</td>\n",
       "      <td>Firebolt</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>101</td>\n",
       "      <td>Pewter Cauldron</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>102</td>\n",
       "      <td>Dragon Hide Gloves</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>103</td>\n",
       "      <td>Polyjuice Potion</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>104</td>\n",
       "      <td>Weasley Is Our King Buttons</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id customerName order_id                      product  quantity\n",
       "0           1   Gryffindor      100                     Firebolt       1.0\n",
       "1           1   Gryffindor      101              Pewter Cauldron      18.0\n",
       "2           2   Hufflepuff      NaN                          NaN       NaN\n",
       "3           3    Ravenclaw      102           Dragon Hide Gloves      10.0\n",
       "4           4    Slytherin      103             Polyjuice Potion       6.0\n",
       "5           4    Slytherin      104  Weasley Is Our King Buttons     120.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   customer_id   6 non-null      object \n",
      " 1   customerName  6 non-null      object \n",
      " 2   order_id      5 non-null      object \n",
      " 3   product       5 non-null      object \n",
      " 4   quantity      5 non-null      float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 372.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "customers = pd.DataFrame(\n",
    "    data={\n",
    "        'customer_id': ['1', '2', '3', '4'],\n",
    "        'customerName': ['Gryffindor', 'Hufflepuff', 'Ravenclaw', 'Slytherin']\n",
    "    }\n",
    ")\n",
    "\n",
    "orders = pd.DataFrame(\n",
    "    data={\n",
    "        'order_id': ['100', '101', '102', '103', '104'],\n",
    "        'customer_id': ['1', '1', '3', '4', '4'],\n",
    "        'product': [\n",
    "            'Firebolt',\n",
    "            'Pewter Cauldron',\n",
    "            'Dragon Hide Gloves',\n",
    "            'Polyjuice Potion',\n",
    "            'Weasley Is Our King Buttons',\n",
    "        ],\n",
    "        'quantity': [1, 18, 10, 6, 120]\n",
    "    }\n",
    ")\n",
    "\n",
    "display(orders)\n",
    "print(orders.info(), '\\n')\n",
    "\n",
    "# left join\n",
    "customer_orders = customers.merge(orders, on='customer_id', how='left')\n",
    "\n",
    "display(customer_orders)\n",
    "print(customer_orders.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unstructured Data\n",
    "Unstructured data is pretty much everything that is not structured data, and it is also the most common data throughout the world. For example, it can't be structured due to having varying string lengths and different potential responders from different speakers.\n",
    "- Common examples of unstructured data:\n",
    "  - Text files, emails, social media comments, website contents, chats or pretty much anything that is freeform text.\n",
    "  - Voice messages, phone calls, audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Processing\n",
    "The difference between data found in many tutorials and data in the real world is that real-world data is rarely clean and homogeneous. In particular, many interesting datasets will have some amount of data missing. To make matters even more complicated, different data sources may indicate missing data in different ways. Therefore, we need to discuss some general considerations for missing data, discuss how Pandas chooses to represent it. For simple solutions, we will use some built-in Pandas tools for handling missing data in Python and we will refer to missing data in general as `null`, `NaN`, or `NA` values.\n",
    "\n",
    "### Trade-offs in Missing Data Conventions\n",
    "There are a number of schemes that have been developed to indicate the presence of missing data in a table or DataFrame. Generally, they revolve around one of two strategies: using a *mask* that globally indicates missing values, or choosing a *sentinel value* that indicates a missing entry. None of these approaches is without trade-offs. Common special values like `NaN` are not available for all data types. As in most cases where no universally optimal choice exists, different languages and systems use different conventions.\n",
    "\n",
    "- In the masking approach, the mask might be an entirely separate Boolean array, or it may involve appropriation of one bit in the data representation to locally indicate the null status of a value. But it requires allocation of an additional Boolean array, which adds overhead in both storage and computation.\n",
    "- In the sentinel approach, the sentinel value could be some data-specific convention, such as indicating a missing integer value with -9999 or some rare bit pattern, or it could be a more global convention, such as indicating a missing floating-point value with NaN (Not a Number), a special value which is part of the IEEE floating-point specification. However, a sentinel value reduces the range of valid values that can be represented, and may require extra (often non-optimized) logic in CPU and GPU arithmetic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data in Pandas\n",
    "The way in which Pandas handles missing values is constrained by its reliance on the NumPy package, which does not have a built-in notion of NA values for non-floating-point data types.\n",
    "\n",
    "Pandas could have followed R's lead in specifying bit patterns for each individual data type to indicate nullness, but this approach turns out to be rather unwieldy.\n",
    "While R contains four basic data types, NumPy supports *far* more than this: for example, while R has a single integer type, NumPy supports *fourteen* basic integer types once you account for available precisions, signedness, and endianness of the encoding.\n",
    "Reserving a specific bit pattern in all available NumPy types would lead to an unwieldy amount of overhead in special-casing various operations for various types, likely even requiring a new fork of the NumPy package. Further, for the smaller data types (such as 8-bit integers), sacrificing a bit to use as a mask will significantly reduce the range of values it can represent.\n",
    "\n",
    "NumPy does have support for masked arrays – that is, arrays that have a separate Boolean mask array attached for marking data as \"good\" or \"bad.\"\n",
    "Pandas could have derived from this, but the overhead in both storage, computation, and code maintenance makes that an unattractive choice.\n",
    "\n",
    "With these constraints in mind, Pandas chose to use sentinels for missing data, and further chose to use two already-existing Python null values: the special floating-point `NaN` value, and the Python `None` object.\n",
    "This choice has some side effects, as we will see, but in practice ends up being a good compromise in most cases of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pythonic missing data\n",
    "The first sentinel value used by Pandas is `None`, a Python singleton object that is often used for missing data in Python code.\n",
    "Because it is a Python object, `None` cannot be used in any arbitrary NumPy/Pandas array, but only in arrays with data type `'object'` (i.e., arrays of Python objects). This ``dtype=object`` means that the best common type representation NumPy could infer for the contents of the array is that they are Python objects. While this kind of object array is useful for some purposes, any operations on the data will be done at the Python level, with much more overhead than the typically fast operations seen for arrays with native types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, None, 3, 4], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "\n",
    "vals1 = np.array([1, None, 3, 4])\n",
    "vals1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype = object\n",
      "81.5 ms ± 2.92 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "dtype = int\n",
      "1.8 ms ± 30 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing computation times by data type\n",
    "for dtype in ['object', 'int']:\n",
    "    print(\"dtype =\", dtype)\n",
    "    %timeit np.arange(1E6, dtype=dtype).sum()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of Python objects in an array also means that if you perform aggregations like ``sum()`` or ``min()`` across an array with a ``None`` value, you will generally get an error. This reflects the fact that addition between an integer and None is undefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvals1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml-lab/data-lab-on-wsl/.venv/lib/python3.11/site-packages/numpy/_core/_methods.py:52\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "vals1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing numerical data\n",
    "The other missing data representation, `NaN` (acronym for *Not a Number*), is different; it is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation. Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code.\n",
    "You should be aware that `NaN` is a bit like a data virus–it infects any other object it touches. Regardless of the operation, the result of arithmetic with `NaN` will be another `NaN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "(1 + np.nan):  nan\n",
      "(0 *  np.nan): nan\n",
      "(Sum, Min, Max of vals2): nan nan nan\n"
     ]
    }
   ],
   "source": [
    "vals2 = np.array([1, np.nan, 3, 4]) \n",
    "print(vals2.dtype)\n",
    "\n",
    "print(\"(1 + np.nan): \", 1 + np.nan)\n",
    "print(\"(0 *  np.nan):\", 0 *  np.nan)\n",
    "\n",
    "# Note that this means that aggregates over the values are well defined (i.e., they don't result in an error) but not always useful.\n",
    "print(\"(Sum, Min, Max of vals2):\", vals2.sum(), vals2.min(), vals2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Sum, Min, Max of vals2 ignoring NaN value): 8.0 1.0 4.0\n"
     ]
    }
   ],
   "source": [
    "# NumPy does provide some special aggregations that will ignore these missing values:\n",
    "print(\"(Sum, Min, Max of vals2 ignoring NaN value):\", np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that ``NaN`` is specifically a floating-point value; there is no equivalent NaN value for integers, strings, or other types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *NaN* and *None* in Pandas\n",
    "`NaN` and `None` both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate. For types that don't have an available sentinel value, Pandas automatically type-casts when *NA* values are present. \n",
    "\n",
    "For example, if we set a value in an integer array to `np.nan`, it will automatically be upcast to a floating-point type to accommodate the *NA*. In addition to casting the integer array to floating point, Pandas automatically converts the `None` to a `NaN` value. (Be aware that there is a proposal to add a native integer NA to Pandas in the future; as of this writing, it has not been included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    NaN\n",
      "2    2.0\n",
      "3    NaN\n",
      "dtype: float64\n",
      "--------\n",
      "0    0\n",
      "1    1\n",
      "dtype: int64\n",
      "--------\n",
      "0    NaN\n",
      "1    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# automatic converting values from 'np.nan' to 'None'\n",
    "x = pd.Series([1, np.nan, 2, None])\n",
    "print(x)\n",
    "print(\"--------\")\n",
    "\n",
    "# create a new integer dataset, and automatic upcasting during \n",
    "x = pd.Series(range(2), dtype=int)\n",
    "print(x)\n",
    "print(\"--------\")\n",
    "\n",
    "x[0] = None\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this type of magic may feel a bit hackish compared to the more unified approach to NA values in domain-specific languages like R, the Pandas sentinel/casting approach works quite well in practice and in my experience only rarely causes issues.\n",
    "\n",
    "The following table lists the upcasting conventions in Pandas when NA values are introduced:\n",
    "|Typeclass     | Conversion When Storing NAs | NA Sentinel Value      |\n",
    "|--------------|-----------------------------|------------------------|\n",
    "| ``floating`` | No change                   | ``np.nan``             |\n",
    "| ``object``   | No change                   | ``None`` or ``np.nan`` |\n",
    "| ``integer``  | Cast to ``float64``         | ``np.nan``             |\n",
    "| ``boolean``  | Cast to ``object``          | ``None`` or ``np.nan`` |\n",
    "\n",
    "Keep in mind that in Pandas, string data is always stored with an ``object`` dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operating on *Null* Values\n",
    "As we have seen, Pandas treats `None` and `NaN` as essentially interchangeable for indicating missing or null values. To facilitate this convention, there are several useful methods for detecting, removing, and replacing null values in Pandas data structures. They are:\n",
    "\n",
    "- `isnull()`: Generate a boolean mask indicating missing values\n",
    "- `notnull()`: Opposite of `isnull()`\n",
    "- `dropna()`: Return a filtered version of the data\n",
    "- `fillna()`: Return a copy of the data with missing values filled or imputed\n",
    "\n",
    "We will conclude this section with a brief exploration and demonstration of these routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Detecting null values*\n",
    "Pandas data structures have two useful methods for detecting null data: `isnull()` and `notnull()`. And boolean masks can be used directly as a ``Series`` or ``DataFrame`` index. The `isnull()` and `notnull()` methods produce similar Boolean results for `DataFrame`s. Either one will return a Boolean mask over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "--------\n",
      "0        1\n",
      "2    hello\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([1, np.nan, 'hello', None])\n",
    "\n",
    "print(data.isnull())\n",
    "print(\"--------\")\n",
    "print(data[data.notnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Dropping null values*\n",
    "In addition to the masking used before, there are the convenience methods, `dropna()` (which removes NA values) and `fillna()` (which fills in NA values). For a `Series`, the result is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "2    hello\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# drop NA values\n",
    "print(data.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a `DataFrame`, there are more options. We cannot drop single values from a `DataFrame`; we can only drop full rows or full columns. Depending on the application, you might want one or the other, so `dropna()` gives a number of options for a `DataFrame`.\n",
    "\n",
    "By default, ``dropna()`` will drop all rows in which *any* null value is present. Consider the following `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "0  1.0  NaN  2\n",
       "1  2.0  3.0  5\n",
       "2  NaN  4.0  6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop NA values from a DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "1  2.0  3.0  5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a new DataFrame has NaN values\n",
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "\n",
    "display(df)\n",
    "\n",
    "# drop NA values from a DataFrame\n",
    "print(\"Drop NA values from a DataFrame:\")\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can drop NA values along a different axis; ``axis=1`` drops all columns containing a null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2\n",
       "0  2\n",
       "1  5\n",
       "2  6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this drops some good data as well; you might rather be interested in dropping rows or columns with *all* NA values, or a majority of NA values. This can be specified through the `how` or `thresh` parameters, which allow fine control of the number of nulls to allow through. The default is `how='any'`, such that any row or column (depending on the `axis` keyword) containing a null value will be dropped.\n",
    "You can also specify `how='all'`, which will only drop rows/columns that are *all* null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2   3\n",
       "0  1.0  NaN  2 NaN\n",
       "1  2.0  3.0  5 NaN\n",
       "2  NaN  4.0  6 NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop all NA values from DataFrame based on column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "0  1.0  NaN  2\n",
       "1  2.0  3.0  5\n",
       "2  NaN  4.0  6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[3] = np.nan\n",
    "display(df)\n",
    "\n",
    "print(\"Drop all NA values from DataFrame based on column:\")\n",
    "df.dropna(axis='columns', how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For finer-grained control, the ``thresh`` parameter lets you specify a minimum number of non-null values for the row/column to be kept. Here the first and last row have been dropped, because they contain only two non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2   3\n",
       "1  2.0  3.0  5 NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis='rows', thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Filling null values*\n",
    "Sometimes rather than dropping NA values, you'd rather replace them with a valid value. This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values. You could do this in-place using the `isnull()` method as a mask, but because it is such a common operation Pandas provides the `fillna()` method, which returns a copy of the array with the null values replaced. Consider the following `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    NaN\n",
       "c    2.0\n",
       "d    NaN\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace NA values with 0:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    0.0\n",
       "c    2.0\n",
       "d    0.0\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace NA values with the previous value:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    1.0\n",
       "c    2.0\n",
       "d    2.0\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace NA values with the next value:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a    1.0\n",
       "b    2.0\n",
       "c    2.0\n",
       "d    3.0\n",
       "e    3.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\n",
    "display(data)\n",
    "\n",
    "# fill NA entries with a single value, such as zero\n",
    "print(\"Replace NA values with 0:\")\n",
    "display(data.fillna(0))\n",
    "\n",
    "# specify a forward-fill to propagate the previous value forward\n",
    "print(\"Replace NA values with the previous value:\")\n",
    "display(data.ffill())\n",
    "\n",
    "# Or specify a back-fill to propagate the next values backward\n",
    "print(\"Replace NA values with the next value:\")\n",
    "display(data.bfill())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "For ``DataFrame``s, the options are similar, but we can also specify an ``axis`` along which the fills take place. Notice that if a previous value is not available during a forward fill, the NA value remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2   3\n",
       "0  1.0  NaN  2 NaN\n",
       "1  2.0  3.0  5 NaN\n",
       "2  NaN  4.0  6 NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  1.0  1.0  2.0  2.0\n",
       "1  2.0  3.0  5.0  5.0\n",
       "2  NaN  4.0  6.0  6.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df)\n",
    "\n",
    "df.ffill(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [Kaggle](https://www.kaggle.com/datasets)\n",
    "- [OpenML](https://www.openml.org/)\n",
    "- [UCI Machien Learning Repository](https://archive.ics.uci.edu/)\n",
    "- [10 minutes to pandas](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
    "- [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
