{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283621eb-cb09-4e8a-af42-1527a58a4fab",
   "metadata": {},
   "source": [
    "# Introduction to the Lab.\n",
    "In this lab learning notebook, you will learn how to build the simplest Language Model (LLM) using Jupyter Notebook. You will build a toy version, prototype, proof of concept, MVP Minimal Viable Product.\n",
    "\n",
    "We will use Python and the nltk library to create a basic language model. This is a minimal viable product (MVP) designed to be as simple as possible while providing a complete and detailed implementation template and set of recipes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c894998-dea3-423b-9997-c05d4c595c83",
   "metadata": {},
   "source": [
    "## Introduction to Language Models \n",
    "A language model is a probabilistic model that is used to predict the likelihood of a sequence of words appearing in a given context. \n",
    "\n",
    "It is commonly used in natural language processing (NLP) tasks such as speech recognition, machine translation, and text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c68acf-6c02-44cc-9ec8-714306b83694",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "In this lab, we will use the Natural Language Toolkit (nltk) library. To install it, open a new cell in your Jupyter Notebook and run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41364be0-7d4b-45bd-9b4f-ec7b50c2d9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pen/ml-lab/ml-on-wsl/.jupyter/lib/python3.11/site-packages/numpy/_core/getlimits.py:551: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n",
      "[nltk_data] Downloading package punkt to /home/pen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# download utilities\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162cf21-7c86-42c0-8e5d-28433db8d539",
   "metadata": {},
   "source": [
    "### Preparing the Dataset \n",
    "For our simple LLM, we will use a sample text. You can replace this with your own dataset if desired. Paste the following code in a new cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912cc519-bb0c-490d-9a3c-b8dce3237bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Once upon a time, in a land far, far away, there lived a king and queen who had a beautiful daughter. The princess was kind and gentle, and everyone loved her.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e12e59-6dab-4687-a53e-ca41d58242c4",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Tokenization is the process of breaking a text into individual words or tokens. \n",
    "\n",
    "We will use the nltk.word_tokenize() function to tokenize our sample text. Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0cffc34-3ff3-483d-800c-63226f07b1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['once', 'upon', 'a', 'time', ',', 'in', 'a', 'land', 'far', ',', 'far', 'away', ',', 'there', 'lived', 'a', 'king', 'and', 'queen', 'who', 'had', 'a', 'beautiful', 'daughter', '.', 'the', 'princess', 'was', 'kind', 'and', 'gentle', ',', 'and', 'everyone', 'loved', 'her', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(sample_text.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f978f9-f434-4bae-a740-940a3263dbbf",
   "metadata": {},
   "source": [
    "### N-Gram Model \n",
    "\n",
    "An N-gram is a contiguous sequence of n items from a given sample of text.\n",
    "\n",
    "We will create a simple bigram model (n=2) for our LLM. This code creates a dictionary of bigrams and their frequencies. Run the following code in a new cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b2ab79-d2c3-4cd0-b748-5d9940d18850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'collections.Counter'>, {'once': Counter({'upon': 1}), 'upon': Counter({'a': 1}), 'a': Counter({'time': 1, 'land': 1, 'king': 1, 'beautiful': 1}), 'time': Counter({',': 1}), ',': Counter({'in': 1, 'far': 1, 'there': 1, 'and': 1}), 'in': Counter({'a': 1}), 'land': Counter({'far': 1}), 'far': Counter({',': 1, 'away': 1}), 'away': Counter({',': 1}), 'there': Counter({'lived': 1}), 'lived': Counter({'a': 1}), 'king': Counter({'and': 1}), 'and': Counter({'queen': 1, 'gentle': 1, 'everyone': 1}), 'queen': Counter({'who': 1}), 'who': Counter({'had': 1}), 'had': Counter({'a': 1}), 'beautiful': Counter({'daughter': 1}), 'daughter': Counter({'.': 1}), '.': Counter({'the': 1}), 'the': Counter({'princess': 1}), 'princess': Counter({'was': 1}), 'was': Counter({'kind': 1}), 'kind': Counter({'and': 1}), 'gentle': Counter({',': 1}), 'everyone': Counter({'loved': 1}), 'loved': Counter({'her': 1}), 'her': Counter({'.': 1})})\n"
     ]
    }
   ],
   "source": [
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq = defaultdict(Counter)\n",
    "\n",
    "for w1, w2 in bigrams:\n",
    "    bigram_freq[w1][w2] += 1\n",
    "\n",
    "print(bigram_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a6c2e-ecff-4356-8976-c4a44cba734a",
   "metadata": {},
   "source": [
    "### Generating Text \n",
    "\n",
    "Now that we have our bigram model, we can use it to generate text. This code defines a function generate_text() that accepts a seed word and generates a sequence of words using the bigram model. Run the following code in a new cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b209c20e-fde4-4158-9bed-aeab492d94a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "princess was kind and everyone loved\n"
     ]
    }
   ],
   "source": [
    "def generate_text(seed, n_words):\n",
    "    result = [seed]\n",
    "    for _ in range(n_words):\n",
    "        next_word_options = bigram_freq[result[-1]]\n",
    "        next_word = random.choices(list(next_word_options.keys()), list(next_word_options.values()))[0]\n",
    "        result.append(next_word)\n",
    "    return ' '.join(result)\n",
    "\n",
    "generated_text = generate_text('princess', 5)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c4de8-d9ce-4724-8a22-ca35ec355acf",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "Congratulations! You have successfully built the simplest LLM using Jupyter Notebook. This basic language model demonstrates the core concepts of NLP, including tokenization and n-grams. \n",
    "\n",
    "Although simple, it can be expanded and improved for more complex applications. Keep experimenting and learning to enhance your NLP skills!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0290fe64-beda-4386-9320-60826c92aef2",
   "metadata": {},
   "source": [
    "## Expanding Your Simplest LLM\n",
    "In this tutorial, we will build upon the simplest LLM we created previously. We will show you how to add more text to your model, train it, and ask more questions to get better answers. We'll cover the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9574e0-82a4-4874-b5b9-d190b5b86088",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ce1afa-75fd-4e1f-ab1e-9a2b58c5cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/pen/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "# download utilities\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ce82b-874b-498c-93d5-bd122bd4b77b",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n",
    "Load your dataset and combine it with new text data. Make sure the new text is clean and well-formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ff7b7d-66f5-459a-996d-6fe376209eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_text = \"your_previous_text_data\"\n",
    "new_text = \"your_new_text_data\"\n",
    "combined_text = old_text + \" \" + new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5aed62-0cfd-4aa9-a917-0f104f355c9d",
   "metadata": {},
   "source": [
    "### Tokenize the text\n",
    "Tokenize the combined text into sentences and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f738f006-8c7f-4416-81af-744fb31edba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = sent_tokenize(combined_text)\n",
    "word_tokens = [word_tokenize(t) for t in sent_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e553b-a372-4f0e-869b-e3aae1b2465b",
   "metadata": {},
   "source": [
    "### Create a trigram model\n",
    "We'll use a trigram model this time, which considers three words at a time, to improve the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a24bdec2-d7f6-4824-9899-432ecca45023",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ae8cf-f63a-4570-b6df-c3cd2d4372a0",
   "metadata": {},
   "source": [
    "### Train the model with more text\n",
    "Instantiate the MLE model and fit it with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed140577-ee9d-4f46-95df-b580c7e9ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLE(n)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df15dae0-f86a-4fec-b2df-9135de302de4",
   "metadata": {},
   "source": [
    "### Generate text with various questions\n",
    "Now, you can ask more questions and generate text based on different input words or phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9ee7a5-b6ef-47f4-ada1-4f2e3d368b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the importance\n",
      "Answer: </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "Question: How does it work\n",
      "Answer: <s> your_previous_text_data your_new_text_data </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "Question: What are the benefits\n",
      "Answer: <s> your_previous_text_data your_new_text_data </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "Question: How can I improve\n",
      "Answer: </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "Question: What should I consider\n",
      "Answer: your_previous_text_data your_new_text_data </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, num_words, model):\n",
    "    word_list = model.generate(num_words, text_seed=prompt.split())\n",
    "    response = ' '.join(word_list)\n",
    "    return response\n",
    "\n",
    "# Example questions\n",
    "questions = [\n",
    "    \"What is the importance\",\n",
    "    \"How does it work\",\n",
    "    \"What are the benefits\",\n",
    "    \"How can I improve\",\n",
    "    \"What should I consider\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {generate_text(question, 20, model)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e48f68-530c-46ae-a26e-e7f420552cac",
   "metadata": {},
   "source": [
    "This expanded LLM will provide more accurate and diverse answers based on the larger dataset. Continue experimenting with different datasets, model architectures, and training techniques to further enhance your NLP skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d11c430-8e05-4d37-b440-2ef5ac5812d9",
   "metadata": {},
   "source": [
    "# References \n",
    "  - [Building the simplest LLM with Jupyter Notebook: A Students Guide](https://coda.io/@peter-sigurdson/building-the-simplest-llm-with-jupyter-notebook-a-students-guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299b0d9-c2e6-45a3-9408-a0c1015ff4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
